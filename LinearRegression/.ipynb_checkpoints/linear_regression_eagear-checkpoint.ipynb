{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "tf.enable_eager_execution()\n",
    "print(tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.random.random((10000,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3554079 , 0.78756617],\n",
       "       [0.20716577, 0.23518073],\n",
       "       [0.32115583, 0.5195119 ],\n",
       "       ...,\n",
       "       [0.00818572, 0.4247306 ],\n",
       "       [0.07348247, 0.14742129],\n",
       "       [0.14403825, 0.86823542]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.array([3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.matmul(X_data, sample_weights.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.21648839, 1.56222025, 3.04151509, ..., 1.72347958, 0.81013255,\n",
       "       3.90505643])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y_data.reshape(len(y_data),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.21648839],\n",
       "       [1.56222025],\n",
       "       [3.04151509],\n",
       "       ...,\n",
       "       [1.72347958],\n",
       "       [0.81013255],\n",
       "       [3.90505643]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to data\n",
    "y_data = np.add(y_data, np.random.uniform(-0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.45713785],\n",
       "       [1.8028697 ],\n",
       "       [3.28216455],\n",
       "       ...,\n",
       "       [1.96412903],\n",
       "       [1.050782  ],\n",
       "       [4.14570588]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Split data to training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42995364, 0.93530176],\n",
       "       [0.6397637 , 0.87535501],\n",
       "       [0.73688362, 0.44080598],\n",
       "       ...,\n",
       "       [0.46649227, 0.21807107],\n",
       "       [0.37316792, 0.45690072],\n",
       "       [0.12865405, 0.36674862]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khai bao bien\n",
    "w = tfe.Variable([[1.0, 1.0]])\n",
    "b = tfe.Variable(np.random.uniform(-0.2, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "def linear_regression(inputs):\n",
    "    return tf.matmul(inputs,w, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function mean square error\n",
    "def loss_function(model_fn, inputs, labels):\n",
    "    return tf.reduce_mean(tf.square(model_fn(inputs) - labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramaters\n",
    "learning_rate = 0.002\n",
    "num_steps = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer  = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# Caculate gradient\n",
    "grad = tfe.implicit_gradients(loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 train loss = 8.544783592224121 test loss = 8.767953872680664\n",
      "Step 100 train loss = 6.785556793212891 test loss = 6.957470893859863\n",
      "Step 200 train loss = 5.389992713928223 test loss = 5.521838188171387\n",
      "Step 300 train loss = 4.282881736755371 test loss = 4.383456230163574\n",
      "Step 400 train loss = 3.4045639038085938 test loss = 3.4807934761047363\n",
      "Step 500 train loss = 2.70772123336792 test loss = 2.765042543411255\n",
      "Step 600 train loss = 2.1548285484313965 test loss = 2.197506904602051\n",
      "Step 700 train loss = 1.7161147594451904 test loss = 1.7474921941757202\n",
      "Step 800 train loss = 1.3679648637771606 test loss = 1.3906569480895996\n",
      "Step 900 train loss = 1.0916608572006226 test loss = 1.107708215713501\n",
      "Step 1000 train loss = 0.8723407983779907 test loss = 0.8833349347114563\n",
      "Step 1100 train loss = 0.6982255578041077 test loss = 0.7054033279418945\n",
      "Step 1200 train loss = 0.5599713921546936 test loss = 0.5642913579940796\n",
      "Step 1300 train loss = 0.45016399025917053 test loss = 0.45236772298812866\n",
      "Step 1400 train loss = 0.3629259169101715 test loss = 0.3635838031768799\n",
      "Step 1500 train loss = 0.2935926616191864 test loss = 0.2931421399116516\n",
      "Step 1600 train loss = 0.23846566677093506 test loss = 0.2372402548789978\n",
      "Step 1700 train loss = 0.1946110874414444 test loss = 0.19286341965198517\n",
      "Step 1800 train loss = 0.15970079600811005 test loss = 0.15762072801589966\n",
      "Step 1900 train loss = 0.13189086318016052 test loss = 0.1296198070049286\n",
      "Step 2000 train loss = 0.10971546173095703 test loss = 0.10735736042261124\n",
      "Step 2100 train loss = 0.09201311320066452 test loss = 0.0896432027220726\n",
      "Step 2200 train loss = 0.07786266505718231 test loss = 0.0755341649055481\n",
      "Step 2300 train loss = 0.06653277575969696 test loss = 0.0642823576927185\n",
      "Step 2400 train loss = 0.05744375288486481 test loss = 0.055295396596193314\n",
      "Step 2500 train loss = 0.05013538524508476 test loss = 0.048103753477334976\n",
      "Step 2600 train loss = 0.04424251616001129 test loss = 0.04233534261584282\n",
      "Step 2700 train loss = 0.03947577625513077 test loss = 0.037695664912462234\n",
      "Step 2800 train loss = 0.03560539335012436 test loss = 0.033951401710510254\n",
      "Step 2900 train loss = 0.032448794692754745 test loss = 0.030917450785636902\n",
      "Step 3000 train loss = 0.029861198738217354 test loss = 0.028447354212403297\n",
      "Step 3100 train loss = 0.027727872133255005 test loss = 0.026425303891301155\n",
      "Step 3200 train loss = 0.025957414880394936 test loss = 0.02475929446518421\n",
      "Step 3300 train loss = 0.02447742410004139 test loss = 0.02337670885026455\n",
      "Step 3400 train loss = 0.023230260238051414 test loss = 0.022219831123948097\n",
      "Step 3500 train loss = 0.022170264273881912 test loss = 0.021243201568722725\n",
      "Step 3600 train loss = 0.021261131390929222 test loss = 0.02041074074804783\n",
      "Step 3700 train loss = 0.02047387696802616 test loss = 0.019693836569786072\n",
      "Step 3800 train loss = 0.019785527139902115 test loss = 0.019069891422986984\n",
      "Step 3900 train loss = 0.019177742302417755 test loss = 0.018520984798669815\n",
      "Step 4000 train loss = 0.018635844811797142 test loss = 0.018032854422926903\n",
      "Step 4100 train loss = 0.018148282542824745 test loss = 0.0175943560898304\n",
      "Step 4200 train loss = 0.017705686390399933 test loss = 0.017196517437696457\n",
      "Step 4300 train loss = 0.017300620675086975 test loss = 0.016832269728183746\n",
      "Step 4400 train loss = 0.016927143558859825 test loss = 0.016496041789650917\n",
      "Step 4500 train loss = 0.016580428928136826 test loss = 0.016183340921998024\n",
      "Step 4600 train loss = 0.01625663787126541 test loss = 0.015890613198280334\n",
      "Step 4700 train loss = 0.015952639281749725 test loss = 0.015615022741258144\n",
      "Step 4800 train loss = 0.015665946528315544 test loss = 0.015354332514107227\n",
      "Step 4900 train loss = 0.015394474379718304 test loss = 0.015106689184904099\n",
      "Step 5000 train loss = 0.015136493369936943 test loss = 0.014870601706206799\n",
      "Step 5100 train loss = 0.014890718273818493 test loss = 0.014644941315054893\n",
      "Step 5200 train loss = 0.014655948616564274 test loss = 0.014428720809519291\n",
      "Step 5300 train loss = 0.014431251212954521 test loss = 0.014221124351024628\n",
      "Step 5400 train loss = 0.014215787872672081 test loss = 0.014021465554833412\n",
      "Step 5500 train loss = 0.014008762314915657 test loss = 0.013829099014401436\n",
      "Step 5600 train loss = 0.013809901662170887 test loss = 0.013643808662891388\n",
      "Step 5700 train loss = 0.013618511147797108 test loss = 0.01346508041024208\n",
      "Step 5800 train loss = 0.013434119522571564 test loss = 0.013292469084262848\n",
      "Step 5900 train loss = 0.013256526552140713 test loss = 0.013125921599566936\n",
      "Step 6000 train loss = 0.01308526936918497 test loss = 0.012965007685124874\n",
      "Step 6100 train loss = 0.012920019216835499 test loss = 0.012809496372938156\n",
      "Step 6200 train loss = 0.01276066992431879 test loss = 0.01265924796462059\n",
      "Step 6300 train loss = 0.012606686912477016 test loss = 0.012513888068497181\n",
      "Step 6400 train loss = 0.012458164244890213 test loss = 0.012373478151857853\n",
      "Step 6500 train loss = 0.0123145692050457 test loss = 0.012237618677318096\n",
      "Step 6600 train loss = 0.012176025658845901 test loss = 0.012106363661587238\n",
      "Step 6700 train loss = 0.012042127549648285 test loss = 0.011979409493505955\n",
      "Step 6800 train loss = 0.011912678368389606 test loss = 0.011856581084430218\n",
      "Step 6900 train loss = 0.011787548661231995 test loss = 0.011737766675651073\n",
      "Step 7000 train loss = 0.011666683480143547 test loss = 0.011622946709394455\n",
      "Step 7100 train loss = 0.011549907736480236 test loss = 0.011511950753629208\n",
      "Step 7200 train loss = 0.011437011882662773 test loss = 0.011404585093259811\n",
      "Step 7300 train loss = 0.011327913030982018 test loss = 0.011300798505544662\n",
      "Step 7400 train loss = 0.011222457513213158 test loss = 0.01120046991854906\n",
      "Step 7500 train loss = 0.01112053357064724 test loss = 0.011103450320661068\n",
      "Step 7600 train loss = 0.011022052727639675 test loss = 0.01100970059633255\n",
      "Step 7700 train loss = 0.0109268669039011 test loss = 0.010919081047177315\n",
      "Step 7800 train loss = 0.010834790766239166 test loss = 0.010831407271325588\n",
      "Step 7900 train loss = 0.01074580941349268 test loss = 0.010746708139777184\n",
      "Step 8000 train loss = 0.010659738443791866 test loss = 0.010664794594049454\n",
      "Step 8100 train loss = 0.010576451197266579 test loss = 0.010585538111627102\n",
      "Step 8200 train loss = 0.010496172122657299 test loss = 0.010509112849831581\n",
      "Step 8300 train loss = 0.010418497957289219 test loss = 0.010435199365019798\n",
      "Step 8400 train loss = 0.010343296453356743 test loss = 0.010363670065999031\n",
      "Step 8500 train loss = 0.010270582512021065 test loss = 0.010294540785253048\n",
      "Step 8600 train loss = 0.010200501419603825 test loss = 0.010227884165942669\n",
      "Step 8700 train loss = 0.010132603347301483 test loss = 0.010163352824747562\n",
      "Step 8800 train loss = 0.010066838935017586 test loss = 0.010100902989506721\n",
      "Step 8900 train loss = 0.010003536008298397 test loss = 0.01004073303192854\n",
      "Step 9000 train loss = 0.009942211210727692 test loss = 0.009982528164982796\n",
      "Step 9100 train loss = 0.009882859885692596 test loss = 0.009926233440637589\n",
      "Step 9200 train loss = 0.00982564315199852 test loss = 0.009871921502053738\n",
      "Step 9300 train loss = 0.009770126082003117 test loss = 0.009819313883781433\n",
      "Step 9400 train loss = 0.00971661414951086 test loss = 0.009768571704626083\n",
      "Step 9500 train loss = 0.00966484472155571 test loss = 0.009719543159008026\n",
      "Step 9600 train loss = 0.009614747948944569 test loss = 0.009672143496572971\n",
      "Step 9700 train loss = 0.009566436521708965 test loss = 0.009626411832869053\n",
      "Step 9800 train loss = 0.009519525803625584 test loss = 0.009582106955349445\n",
      "Step 9900 train loss = 0.009474437683820724 test loss = 0.009539443999528885\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "for step in range(num_steps):\n",
    "    optimizer.apply_gradients(grad(linear_regression, np.float32(X_train), np.float32(y_train)))\n",
    "    if step % 100 ==0:\n",
    "        train_loss = loss_function(linear_regression, np.float32(X_train), np.float32(y_train))\n",
    "        test_loss = loss_function(linear_regression, np.float32(X_test), np.float32(y_test))\n",
    "        print (\"Step {} train loss = {} test loss = {}\".format(step, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.296268, 4.12008 ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039656814"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_regression(np.float32(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=181828, shape=(2000, 1), dtype=float32, numpy=\n",
       "array([[1.7951915],\n",
       "       [1.6602296],\n",
       "       [1.6849046],\n",
       "       ...,\n",
       "       [5.683131 ],\n",
       "       [2.5161734],\n",
       "       [1.7173572]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.89041796],\n",
       "       [1.79664285],\n",
       "       [1.85306687],\n",
       "       ...,\n",
       "       [5.60553955],\n",
       "       [2.60749424],\n",
       "       [1.82365965]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorflowTutorial",
   "language": "python",
   "name": "tensorflowtutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
