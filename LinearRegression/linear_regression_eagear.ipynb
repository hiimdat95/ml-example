{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "tf.enable_eager_execution()\n",
    "print(tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.random.random((10000,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00524662, 0.11702478],\n",
       "       [0.03004481, 0.83221913],\n",
       "       [0.03621821, 0.39181878],\n",
       "       ...,\n",
       "       [0.21744713, 0.42617115],\n",
       "       [0.43377152, 0.88005568],\n",
       "       [0.50909975, 0.94577261]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.array([3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.matmul(X_data, sample_weights.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48383899, 3.41901093, 1.67592974, ..., 2.35702597, 4.82153728,\n",
       "       5.31038969])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y_data.reshape(len(y_data),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48383899],\n",
       "       [3.41901093],\n",
       "       [1.67592974],\n",
       "       ...,\n",
       "       [2.35702597],\n",
       "       [4.82153728],\n",
       "       [5.31038969]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to data\n",
    "y_data = np.add(y_data, np.random.uniform(-0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41596615],\n",
       "       [3.35113809],\n",
       "       [1.60805691],\n",
       "       ...,\n",
       "       [2.28915313],\n",
       "       [4.75366444],\n",
       "       [5.24251686]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Split data to training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58408645, 0.17542469],\n",
       "       [0.13420993, 0.01351474],\n",
       "       [0.81999127, 0.22493859],\n",
       "       ...,\n",
       "       [0.16918431, 0.78667633],\n",
       "       [0.74732915, 0.88505324],\n",
       "       [0.59212997, 0.15430513]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khai bao bien\n",
    "w = tfe.Variable([[1.0, 1.0]])\n",
    "b = tfe.Variable(np.random.uniform(-0.2, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "def linear_regression(inputs):\n",
    "    return tf.matmul(inputs,w, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function mean square error\n",
    "def loss_function(model_fn, inputs, labels):\n",
    "    return tf.reduce_mean(tf.square(model_fn(inputs) - labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramaters\n",
    "learning_rate = 0.002\n",
    "num_steps = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer  = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# Caculate gradient\n",
    "grad = tfe.implicit_gradients(loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 train loss = 7.04918909072876 test loss = 6.976617813110352\n",
      "Step 100 train loss = 4.406541347503662 test loss = 4.364357948303223\n",
      "Step 200 train loss = 2.758683204650879 test loss = 2.7347662448883057\n",
      "Step 300 train loss = 1.7308827638626099 test loss = 1.717836856842041\n",
      "Step 400 train loss = 1.0895849466323853 test loss = 1.0829213857650757\n",
      "Step 500 train loss = 0.689218282699585 test loss = 0.6862300038337708\n",
      "Step 600 train loss = 0.43906036019325256 test loss = 0.43813034892082214\n",
      "Step 700 train loss = 0.28255948424339294 test loss = 0.2827324867248535\n",
      "Step 800 train loss = 0.18446679413318634 test loss = 0.1851881742477417\n",
      "Step 900 train loss = 0.12281285226345062 test loss = 0.12376752495765686\n",
      "Step 1000 train loss = 0.08390292525291443 test loss = 0.08491823077201843\n",
      "Step 1100 train loss = 0.05919891223311424 test loss = 0.060185279697179794\n",
      "Step 1200 train loss = 0.043377745896577835 test loss = 0.044293101876974106\n",
      "Step 1300 train loss = 0.033119797706604004 test loss = 0.033948615193367004\n",
      "Step 1400 train loss = 0.026354709640145302 test loss = 0.02709546685218811\n",
      "Step 1500 train loss = 0.021790042519569397 test loss = 0.022448157891631126\n",
      "Step 1600 train loss = 0.018618976697325706 test loss = 0.019202718511223793\n",
      "Step 1700 train loss = 0.016337299719452858 test loss = 0.016855673864483833\n",
      "Step 1800 train loss = 0.014629325829446316 test loss = 0.015090936794877052\n",
      "Step 1900 train loss = 0.013297167606651783 test loss = 0.0137097779661417\n",
      "Step 2000 train loss = 0.012216363102197647 test loss = 0.012586690485477448\n",
      "Step 2100 train loss = 0.011308042332530022 test loss = 0.011641794815659523\n",
      "Step 2200 train loss = 0.010522245429456234 test loss = 0.01082422025501728\n",
      "Step 2300 train loss = 0.009826847352087498 test loss = 0.010101036168634892\n",
      "Step 2400 train loss = 0.009200838394463062 test loss = 0.009450568817555904\n",
      "Step 2500 train loss = 0.008630394004285336 test loss = 0.008858444169163704\n",
      "Step 2600 train loss = 0.008106065914034843 test loss = 0.008314757607877254\n",
      "Step 2700 train loss = 0.007621141150593758 test loss = 0.007812432013452053\n",
      "Step 2800 train loss = 0.007170893717557192 test loss = 0.0073464433662593365\n",
      "Step 2900 train loss = 0.006751759443432093 test loss = 0.006912992335855961\n",
      "Step 3000 train loss = 0.006360800005495548 test loss = 0.006508939433842897\n",
      "Step 3100 train loss = 0.005995654035359621 test loss = 0.00613177428022027\n",
      "Step 3200 train loss = 0.005654375068843365 test loss = 0.0057794200256466866\n",
      "Step 3300 train loss = 0.005335175432264805 test loss = 0.005449979566037655\n",
      "Step 3400 train loss = 0.005036537069827318 test loss = 0.005141850095242262\n",
      "Step 3500 train loss = 0.004757075570523739 test loss = 0.004853568039834499\n",
      "Step 3600 train loss = 0.0044954996556043625 test loss = 0.004583782982081175\n",
      "Step 3700 train loss = 0.004250654485076666 test loss = 0.004331288859248161\n",
      "Step 3800 train loss = 0.004021428991109133 test loss = 0.0040949201211333275\n",
      "Step 3900 train loss = 0.0038068376015871763 test loss = 0.0038736567366868258\n",
      "Step 4000 train loss = 0.003605947596952319 test loss = 0.003666527336463332\n",
      "Step 4100 train loss = 0.0034178476780653 test loss = 0.0034725877922028303\n",
      "Step 4200 train loss = 0.003241761587560177 test loss = 0.0032910367008298635\n",
      "Step 4300 train loss = 0.0030768699944019318 test loss = 0.003121023066341877\n",
      "Step 4400 train loss = 0.002922509564086795 test loss = 0.002961862599477172\n",
      "Step 4500 train loss = 0.002777970163151622 test loss = 0.0028128251433372498\n",
      "Step 4600 train loss = 0.002642647363245487 test loss = 0.002673282753676176\n",
      "Step 4700 train loss = 0.002515933243557811 test loss = 0.0025426119100302458\n",
      "Step 4800 train loss = 0.0023973092902451754 test loss = 0.0024202754721045494\n",
      "Step 4900 train loss = 0.002286245347931981 test loss = 0.0023057283833622932\n",
      "Step 5000 train loss = 0.0021822561975568533 test loss = 0.0021984707564115524\n",
      "Step 5100 train loss = 0.00208488292992115 test loss = 0.0020980278495699167\n",
      "Step 5200 train loss = 0.001993714366108179 test loss = 0.002003979869186878\n",
      "Step 5300 train loss = 0.0019083566730841994 test loss = 0.0019159183138981462\n",
      "Step 5400 train loss = 0.0018284397665411234 test loss = 0.0018334622727707028\n",
      "Step 5500 train loss = 0.0017536248778924346 test loss = 0.0017562624998390675\n",
      "Step 5600 train loss = 0.001683560200035572 test loss = 0.0016839585732668638\n",
      "Step 5700 train loss = 0.0016179605154320598 test loss = 0.0016162553802132607\n",
      "Step 5800 train loss = 0.0015565560897812247 test loss = 0.0015528751537203789\n",
      "Step 5900 train loss = 0.0014990568161010742 test loss = 0.0014935199869796634\n",
      "Step 6000 train loss = 0.0014452151954174042 test loss = 0.0014379345811903477\n",
      "Step 6100 train loss = 0.0013948034029453993 test loss = 0.001385883311741054\n",
      "Step 6200 train loss = 0.0013476087478920817 test loss = 0.0013371489476412535\n",
      "Step 6300 train loss = 0.0013034236617386341 test loss = 0.0012915157712996006\n",
      "Step 6400 train loss = 0.0012620583875104785 test loss = 0.0012487894855439663\n",
      "Step 6500 train loss = 0.0012233180459588766 test loss = 0.0012087698560208082\n",
      "Step 6600 train loss = 0.0011870355810970068 test loss = 0.0011712843552231789\n",
      "Step 6700 train loss = 0.001153092598542571 test loss = 0.0011362105142325163\n",
      "Step 6800 train loss = 0.0011212814133614302 test loss = 0.0011033351765945554\n",
      "Step 6900 train loss = 0.0010915269376710057 test loss = 0.0010725805768743157\n",
      "Step 7000 train loss = 0.0010636569932103157 test loss = 0.0010437696473672986\n",
      "Step 7100 train loss = 0.0010375521378591657 test loss = 0.0010167787550017238\n",
      "Step 7200 train loss = 0.0010131074814125896 test loss = 0.0009915009140968323\n",
      "Step 7300 train loss = 0.000990237225778401 test loss = 0.0009678461356088519\n",
      "Step 7400 train loss = 0.0009688186692073941 test loss = 0.0009456897969357669\n",
      "Step 7500 train loss = 0.0009487628703936934 test loss = 0.0009249385911971331\n",
      "Step 7600 train loss = 0.0009299831581301987 test loss = 0.0009055046830326319\n",
      "Step 7700 train loss = 0.0009124159114435315 test loss = 0.0008873217739164829\n",
      "Step 7800 train loss = 0.0008959625847637653 test loss = 0.0008702886989340186\n",
      "Step 7900 train loss = 0.0008805485558696091 test loss = 0.0008543279254809022\n",
      "Step 8000 train loss = 0.000866107817273587 test loss = 0.0008393715252168477\n",
      "Step 8100 train loss = 0.0008526149322278798 test loss = 0.0008253942942246795\n",
      "Step 8200 train loss = 0.0008399536018259823 test loss = 0.000812274869531393\n",
      "Step 8300 train loss = 0.0008281237096525729 test loss = 0.0008000144152902067\n",
      "Step 8400 train loss = 0.0008170185028575361 test loss = 0.0007885022787377238\n",
      "Step 8500 train loss = 0.0008066538721323013 test loss = 0.0007777554565109313\n",
      "Step 8600 train loss = 0.0007969244616106153 test loss = 0.0007676646928302944\n",
      "Step 8700 train loss = 0.0007878196192905307 test loss = 0.0007582189282402396\n",
      "Step 8800 train loss = 0.0007793091353960335 test loss = 0.000749387254472822\n",
      "Step 8900 train loss = 0.0007713307859376073 test loss = 0.0007411051192320883\n",
      "Step 9000 train loss = 0.0007638512761332095 test loss = 0.0007333393441513181\n",
      "Step 9100 train loss = 0.0007568462169729173 test loss = 0.0007260630372911692\n",
      "Step 9200 train loss = 0.000750306120608002 test loss = 0.0007192681077867746\n",
      "Step 9300 train loss = 0.0007441798225045204 test loss = 0.0007129008881747723\n",
      "Step 9400 train loss = 0.0007384419441223145 test loss = 0.0007069355924613774\n",
      "Step 9500 train loss = 0.0007330679218284786 test loss = 0.0007013462600298226\n",
      "Step 9600 train loss = 0.0007280351710505784 test loss = 0.0006961102481000125\n",
      "Step 9700 train loss = 0.0007233209325931966 test loss = 0.0006912035751156509\n",
      "Step 9800 train loss = 0.0007189046591520309 test loss = 0.0006866054609417915\n",
      "Step 9900 train loss = 0.0007147680153138936 test loss = 0.0006822961731813848\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "for step in range(num_steps):\n",
    "    optimizer.apply_gradients(grad(linear_regression, np.float32(X_train), np.float32(y_train)))\n",
    "    if step % 100 ==0:\n",
    "        train_loss = loss_function(linear_regression, np.float32(X_train), np.float32(y_train))\n",
    "        test_loss = loss_function(linear_regression, np.float32(X_test), np.float32(y_test))\n",
    "        print (\"Step {} train loss = {} test loss = {}\".format(step, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.9612942, 3.922976 ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.17148267"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_regression(np.float32(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=181828, shape=(2000, 1), dtype=float32, numpy=\n",
       "array([[4.502651 ],\n",
       "       [3.7337623],\n",
       "       [4.333744 ],\n",
       "       ...,\n",
       "       [3.8940823],\n",
       "       [1.8579803],\n",
       "       [2.586601 ]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.5058752 ],\n",
       "       [3.7311503 ],\n",
       "       [4.33921611],\n",
       "       ...,\n",
       "       [3.90181952],\n",
       "       [1.81709078],\n",
       "       [2.56527698]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21416796470>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(y_test[:20])), y_test[:20],'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2141688c908>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(y_pred.numpy()[:20])), y_pred.numpy()[:20],'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorflowTutorial",
   "language": "python",
   "name": "tensorflowtutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
